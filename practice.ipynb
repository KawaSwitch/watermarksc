{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "# from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "# from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "# from keras.models import Sequential, Model\n",
    "# #from keras.optimizers import Adam\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "# from keras.backend import tensorflow_backend\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import rarfile as rar\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "root_dir = str(Path('img').resolve())\n",
    "class_names = os.listdir(root_dir)\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# print(keras.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.class_names = os.listdir(root_dir)\n",
    "\n",
    "        self.shape = (8, 8, 1) #(8, 8, 3)\n",
    "        self.z_dim = 100\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        ori_noise, self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        #tf.compat.v1.disable_eager_execution()\n",
    "        \n",
    "        z = tf.keras.Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        #print(tf.shape(img))\n",
    "        \n",
    "        \n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        \n",
    "#         with tf.compat.v1.Session() as sess:\n",
    "#             sess.run(init)\n",
    "        sess = tf.compat.v1.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "        elems = img\n",
    "        \n",
    "        \n",
    "        print(\"imgs shape (before mapping): \" + str(elems.shape))\n",
    "        op = tf.map_fn(self.wavelet, elems)\n",
    "        result = sess.run(op)\n",
    "\n",
    "        for elem in elems:\n",
    "            print('hoge', type(elem))\n",
    "\n",
    "        \n",
    "#         print(type(img))\n",
    "#         print(tf.shape(img))\n",
    "        img = self.wavelet(img)\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    # must under eagar mode\n",
    "    def tensor_to_array(self, tensor1):\n",
    "        return np.array(tensor1)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(layers.Dense(128 * 8 * 8, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(layers.Reshape((8, 8, 128)))\n",
    "        model.add(layers.BatchNormalization(momentum=0.8))\n",
    "        #model.add(UpSampling2D())\n",
    "        model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "        model.add(layers.BatchNormalization(momentum=0.8))\n",
    "        #model.add(UpSampling2D())\n",
    "        model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "        model.add(layers.BatchNormalization(momentum=0.8))\n",
    "        model.add(layers.Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "        model.add(layers.Activation(\"tanh\"))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        noise = keras.Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        print(img.shape)\n",
    "\n",
    "        return noise, keras.Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "\n",
    "        #4 機械学習（人工知能）モデルの作成\n",
    "        #2021/6/2「Conv2D」を使ってディープラーニング技術でおなじみの「畳み込みニューラルネットワーク」（CNN）を実装\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Conv2D(48, (2, 2), padding='same', input_shape=(8, 8, 1), activation='relu'))\n",
    "        model.add(layers.Conv2D(128, (2, 2), padding='same', activation='relu'))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "            \n",
    "        img = keras.Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        #model.summary()\n",
    "\n",
    "        return keras.Model(img, validity)\n",
    "    \n",
    "    def build_discriminator2(self):\n",
    "        \n",
    "        img_shape = self.shape\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(48, (1, 1), padding='same', input_shape=(4, 4, 3), activation='relu'))\n",
    "        model.add(Conv2D(128, (2, 2), padding='same', activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        \n",
    "#         w_image = np.zeros((4, 4, 3))\n",
    "#         for num in range(0, 4):\n",
    "#             for ber in range(0, 4):\n",
    "#                 w_image[num][ber][0] = (img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4\n",
    "#                 w_image[num][ber][1] = (img[num*2][ber*2] + img[num*2+1][ber*2] - img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4\n",
    "#                 w_image[num][ber][2] = (img[num*2][ber*2] - img[num*2+1][ber*2] - img[num*2][ber*2+1] + img[num*2+1][ber*2+1]) / 4\n",
    "        #w_images.append(w_image)\n",
    "        validity = model(img)\n",
    "        \n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=1000, check_noise=None, r=5, c=5):\n",
    "\n",
    "        X_train, labels = self.load_imgs()\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "\n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "            model_dir = Path('ganmodels')\n",
    "            model_dir.mkdir(exist_ok=True)\n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    self.generator.save(str(model_dir)+\"/dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        #print(type(gen_imgs)\n",
    "        gen_imgs = np.squeeze(gen_imgs)\n",
    "        print(gen_imgs.shape)\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :])#, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig('images/gen_imgs/watermark_%d.png' % iteration)\n",
    "\n",
    "        plt.close()\n",
    "        \n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "\n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "\n",
    "        return label_hot\n",
    "\n",
    "    def load_imgs(self, ret_wavelet=False):\n",
    "\n",
    "#         img_paths = []\n",
    "#         labels = []\n",
    "#         images = []\n",
    "#         for cl_name in self.class_names:\n",
    "#             img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "#             for img_name in img_names:\n",
    "#                 img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "#                 hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "#                 labels.append(hot_cl_name)\n",
    "\n",
    "#         for img_path in img_paths:\n",
    "#             img = cv2.imread(img_path)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#             images.append(img)\n",
    "\n",
    "#         images = np.array(images)\n",
    "\n",
    "#        return (np.array(images), np.array(labels))\n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "        w_images = []\n",
    "\n",
    "        for cl_name in class_names:\n",
    "            print(cl_name)\n",
    "            img_dir_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "            for img_dir_name in img_dir_names:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name, img_dir_name))\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_dir_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "\n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # (8, 8, 3) -> (8, 8, 1)へ次元を削減 すべて同じ値なので\n",
    "            img = np.delete(img, [1, 2], 2)\n",
    "            images.append(img)\n",
    "            w_image = np.zeros((4, 4, 3))\n",
    "            MM_image = np.zeros((4,4,2))\n",
    "            for num in range(0, 4):\n",
    "                for ber in range(0, 4):\n",
    "                    w_image[num][ber][0] = (img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4\n",
    "                    w_image[num][ber][1] = (img[num*2][ber*2] + img[num*2+1][ber*2] - img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4\n",
    "                    w_image[num][ber][2] = (img[num*2][ber*2] - img[num*2+1][ber*2] - img[num*2][ber*2+1] + img[num*2+1][ber*2+1]) / 4\n",
    "                    MM_image[num][ber][0] = max([w_image[num][ber][0],w_image[num][ber][1],w_image[num][ber][2]])\n",
    "                    MM_image[num][ber][1] = min([w_image[num][ber][0],w_image[num][ber][1],w_image[num][ber][2]])\n",
    "            #w_images.append(MM_image)\n",
    "            w_images.append(w_image)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        if ret_wavelet:\n",
    "            return np.array(w_images), np.array(labels)\n",
    "        else:\n",
    "            return np.array(images), np.array(labels)\n",
    "\n",
    "   \n",
    "\n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "\n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "\n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "\n",
    "        vectors = np.array(vectors)\n",
    "\n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "\n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = gen_img #cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "\n",
    "        return resultImage\n",
    "    \n",
    "    def wavelet(self, img):\n",
    "        #images.append(img)\n",
    "\n",
    "        print(img)\n",
    "        w_images = []\n",
    "        print(\"img shape (after mapping):\", img.shape)\n",
    "        \n",
    "        \n",
    "#         w_image = tf.Variable(tf.zeros((4,4,3)))\n",
    "        #w_image = tf.zeros((4,4,3))\n",
    "        wave = tf.Variable(lambda: tf.zeros([4,4,3]))\n",
    "#         wave = tf.Variable(lambda : tf.random.truncated_normal([10, 40]))\n",
    "\n",
    "\n",
    "#         op = tf.assign(w_image, wavelet_test(w_image, img))\n",
    "#         with tf.Session() as sess:\n",
    "#             sess.run(tf.global_variables_initializer())\n",
    "#             ret = sess.run(op)\n",
    "#             print(type(ret)) # <class 'numpy.ndarray'>\n",
    "#             print(ret)\n",
    "#         w_image = tf.zeros(shape=[4, 4, 3])\n",
    "  \n",
    "#         #MM_image = np.zeros((4,4,2))\n",
    "#         for num in range(0, 4):\n",
    "#             for ber in range(0, 4):\n",
    "#                 print((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]))\n",
    "#                 w_image[num][ber][0].assign((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "#                 w_image[num][ber][1].assign((img[num*2][ber*2] + img[num*2+1][ber*2] - img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "#                 w_image[num][ber][2].assign((img[num*2][ber*2] - img[num*2+1][ber*2] - img[num*2][ber*2+1] + img[num*2+1][ber*2+1]) / 4)\n",
    "                #MM_image[num][ber][0] = max([w_image[num][ber][0],w_image[num][ber][1],w_image[num][ber][2]])\n",
    "                #MM_image[num][ber][1] = min([w_image[num][ber][0],w_image[num][ber][1],w_image[num][ber][2]])\n",
    "            #w_images.append(MM_image)\n",
    "            #w_images.append(w_image)\n",
    "            \n",
    "        a = img[0::2,0::2]\n",
    "        b = img[0::2,1::2]\n",
    "        c = img[1::2,0::2]\n",
    "        d = img[1::2,1::2]\n",
    "        \n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(a)\n",
    "        \n",
    "        test = np.zeros((8,8))\n",
    "        \n",
    "        #print(img.numpy())\n",
    "        \n",
    "        LL = (a + b + c + d) / 4\n",
    "        LH = (a - b + c - d) / 4\n",
    "        HL = (a + b - c - d) / 4\n",
    "        HH = (a - b - c + d) / 4\n",
    "        \n",
    "#          wave[:][:][0].assign(LL)\n",
    "#          wave[:][:][1] = LH\n",
    "#          wave[:][:][2] = HL\n",
    "#          wave[:][:][3] = HH\n",
    "#         wave(:,:,0) = LL\n",
    "#         wave(:,:,1) = LH\n",
    "#         wave(:,:,2) = HL\n",
    "#         wave(:,:,3) = HH\n",
    "        \n",
    "        #print(wave)\n",
    "        #images = np.array(images)\n",
    "\n",
    "        #if ret_wavelet:\n",
    "        #return np.array(w_image)\n",
    "        return wave\n",
    "        #else:\n",
    "            #return np.array(images), np.array(labels)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 8, 8, 48)          240       \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 8, 8, 128)         24704     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,073,777\n",
      "Trainable params: 1,073,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 8, 8, 1)\n",
      "imgs shape (before mapping): (None, 8, 8, 1)\n",
      "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(8, 8, 1), dtype=float32)\n",
      "img shape (after mapping): (8, 8, 1)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Tensor(\"strided_slice:0\", shape=(4, 4, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[node input_28 (defined at <ipython-input-73-016a4d780a08>:20) ]]\n\t [[map_8/TensorArrayV2Stack/TensorListStack/_9]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[node input_28 (defined at <ipython-input-73-016a4d780a08>:20) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'input_28':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-74-181e2fc960c8>\", line 3, in <module>\n    dcgan = DCGAN()\n  File \"<ipython-input-73-016a4d780a08>\", line 20, in __init__\n    z = tf.keras.Input(shape=(self.z_dim,))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 386, in Input\n    input_layer = InputLayer(**input_layer_config)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 204, in __init__\n    ragged=ragged)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\", line 1367, in placeholder\n    x = array_ops.placeholder(dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 3271, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6746, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3565, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[{{node input_28}}]]\n\t [[map_8/TensorArrayV2Stack/TensorListStack/_9]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[{{node input_28}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-181e2fc960c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcheck_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-016a4d780a08>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imgs shape (before mapping): \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavelet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[node input_28 (defined at <ipython-input-73-016a4d780a08>:20) ]]\n\t [[map_8/TensorArrayV2Stack/TensorListStack/_9]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_28' with dtype float and shape [?,100]\n\t [[node input_28 (defined at <ipython-input-73-016a4d780a08>:20) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'input_28':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-74-181e2fc960c8>\", line 3, in <module>\n    dcgan = DCGAN()\n  File \"<ipython-input-73-016a4d780a08>\", line 20, in __init__\n    z = tf.keras.Input(shape=(self.z_dim,))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 386, in Input\n    input_layer = InputLayer(**input_layer_config)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 204, in __init__\n    ragged=ragged)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\", line 1367, in placeholder\n    x = array_ops.placeholder(dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 3271, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6746, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3565, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    dcgan = DCGAN()\n",
    "    \n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(iterations=200000, batch_size=32, save_interval=1000,\n",
    "                model_interval=5000, check_noise=check_noise, r=r,c=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    a = np.array([[1, 2]])\n",
    "    b = np.array([1, 2])\n",
    "    \n",
    "    \n",
    "    print(a.shape, b.shape)\n",
    "    \n",
    "\n",
    "    const1 = tf.constant(2)\n",
    "    const2 = tf.constant(3, dtype=tf.float32)\n",
    "    add_op = tf.add(const1, const2) # 2 + 3\n",
    "    w = tf.zeros([3, 2])\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         result = sess.run(tf.add(w, const2))\n",
    "#         print(result)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    a = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            a[i,j] = 10*i+j\n",
    "    return a\n",
    "\n",
    "def func2(x, adder):\n",
    "    a = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            a[i,j] = 10*i+j + adder\n",
    "\n",
    "def func3(x, adder):\n",
    "    a = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            a[i,j] = 10*i+j + adder\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params x: (?, ?, 3)\n",
    "def wavelet_test(x, img, w, h):\n",
    "    x = np.zeros(x.shape)\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    print(h, w)\n",
    "#     for num in range(0, w//2):\n",
    "#         for ber in range(0, h//2):\n",
    "# #             print((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]))\n",
    "#             x[num][ber][0].assign((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "#             x[num][ber][1].assign((img[num*2][ber*2] + img[num*2+1][ber*2] - img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "#             x[num][ber][2].assign((img[num*2][ber*2] - img[num*2+1][ber*2] - img[num*2][ber*2+1] + img[num*2+1][ber*2+1]) / 4)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params x: (?, ?, 3)\n",
    "def wavelet_internal(x, img, w, h):\n",
    "    x = np.zeros(x.shape)\n",
    "    \n",
    "    for num in range(0, w//2):\n",
    "        for ber in range(0, h//2):\n",
    "#             print((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]))\n",
    "            x[num][ber][0].assign((img[num*2][ber*2] - img[num*2+1][ber*2] + img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "            x[num][ber][1].assign((img[num*2][ber*2] + img[num*2+1][ber*2] - img[num*2][ber*2+1] - img[num*2+1][ber*2+1]) / 4)\n",
    "            x[num][ber][2].assign((img[num*2][ber*2] - img[num*2+1][ber*2] - img[num*2][ber*2+1] + img[num*2+1][ber*2+1]) / 4)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[2., 2., 2.],\n",
      "       [2., 2., 2.],\n",
      "       [2., 2., 2.],\n",
      "       [2., 2., 2.]], dtype=float32)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <tf.Variable 'UnreadVariable' shape=(4, 3) dtype=float32> has invalid type <class 'tensorflow.python.ops.resource_variable_ops._UnreadVariable'>, must be a string or Tensor. (Can not convert a _UnreadVariable into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    306\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 307\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3754\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3755\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3843\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[0;32m-> 3844\u001b[0;31m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   3845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a _UnreadVariable into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fe7a9b5c86a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <class 'numpy.ndarray'>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1176\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \"\"\"\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    310\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    312\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument <tf.Variable 'UnreadVariable' shape=(4, 3) dtype=float32> has invalid type <class 'tensorflow.python.ops.resource_variable_ops._UnreadVariable'>, must be a string or Tensor. (Can not convert a _UnreadVariable into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "x = tf.Variable(lambda: tf.zeros((4,3)))\n",
    "print(x)\n",
    "y = copy.deepcopy(x)\n",
    "tf.compat.v1.assign(x, x+2)\n",
    "print(x)\n",
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     sess.run(tf.compat.v1.global_variables_initializer())\n",
    "#     ret = sess.run(op)\n",
    "#     print(type(ret)) # <class 'numpy.ndarray'>\n",
    "#     print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_2:0\", shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'np'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-44a1f962d7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'np'"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "print(e)\n",
    "print(e.np())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = lambda a, b=1 : a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/py/in_report\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
